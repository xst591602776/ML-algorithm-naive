机器学习和人工智能，深度学习的关系

   机器学习是人工智能的一个实现途径

   深度学习是机器学习的一个方法发展而来

达特茅斯会议-人工智能元年

​	会议内容 人工智能



机器学习定义

从数据中自动分析获得模型，并利用模型对未知数据进行预测。

从大量的日常经验中归纳规律，当面临新的问题的时候，就可以利用以往总结的规律去分析现实状况，采取最佳策略。

机器学习 = 数据（data） + 模型（model） + 优化方法（optimal strategy）



数据分为结构化数据和非结构化数据







机器学习的应用场景非常多，包括医疗、航空、教育、物流、电商等领域。

举例

1.从数据（大量的猫和狗的图片）中自动分析获得模型（辨别猫和狗的规律），从而使机器拥有识别猫和狗的能力。



2.从数据（房屋的各种信息）中自动分析获得模型（判断房屋价格的规律），从而使机器拥有预测房屋价格的能力。

有监督学习和无监督学习区别

监督学习： 输入数据——有特征有标签，即有标准答案

非监督学习：输入数据——有特征无标签，即无标准答案





监督学习(supervised learning)（预测）

定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值(称为回归），或是输出是有限个离散值（称作分类）。

分类 k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络

回归 线性回归、岭回归

无监督学习(unsupervised learning)

定义：输入数据是由输入特征值所组成。

聚类 k-means







监督学习(supervised learning)（预测）

定义：输入数据是由输入特征值和目标值所组成。函数的输出可以是一个连续的值(称为回归），或是输出是有限个离散值（称作分类）。

分类 k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归、神经网络

回归 线性回归、岭回归

无监督学习(unsupervised learning)

定义：输入数据是由输入特征值所组成。

聚类 k-means





机器学习开发流程

<img src="/var/folders/ff/2q8cpg353gd7915tykkbkwp00000gn/T/com.yinxiang.Mac/com.yinxiang.Mac/WebKitDnD.DgxWKo/屏幕快照 2020-01-02 下午2.50.18.png" alt="屏幕快照 2020-01-02 下午2.50.18" style="zoom:80%;" />



数据集构成

特征值+目标值

举例

![屏幕快照 2020-01-02 下午2.44.08](/var/folders/ff/2q8cpg353gd7915tykkbkwp00000gn/T/com.yinxiang.Mac/com.yinxiang.Mac/WebKitDnD.5Nc0Kl/屏幕快照 2020-01-02 下午2.44.08.png)



 Loss Function、Cost Function 和 Objective Function 的区别和联系



- \- 损失函数 Loss Function 通常是**针对单个训练样本而言**，给定一个模型输出 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D) 和一个真实 ![[公式]](https://www.zhihu.com/equation?tex=y) ，损失函数输出一个实值损失 ![[公式]](https://www.zhihu.com/equation?tex=L%3Df%28y_i%2C+%5Chat%7By_i%7D%29)
- \- 代价函数 Cost Function 通常是**针对整个训练集**（或者在使用 mini-batch gradient descent 时一个 mini-batch）的总损失 ![[公式]](https://www.zhihu.com/equation?tex=J%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+f%28y_i%2C%5Chat%7By_i%7D%29)
- \- 目标函数 Objective Function 是一个更通用的术语，表示任意希望被优化的函数，用于机器学习领域和非机器学习领域（比如运筹优化）

一句话总结三者的关系就是：[A loss function is a part of a cost function which is a type of an objective function.]



### 基础概念

损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，换句话，可以解释为我们构建模型得到的预测值与真实值之间的差距。它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：

![img](https://img2018.cnblogs.com/blog/981211/201810/981211-20181022092825177-881167066.png)

整个公式分为两个部分，前面部分是损失函数，后面部分是正则项，正则项常用的有L1和L2正则项，目的是防止过拟合。





几个基本的机器学习损失函数

### 1）0-1损失

常用于二分类问题，0-1损失不连续、非凸，优化困难，0-1损失对每个错分类点都施以相同的惩罚，这样那些“错的离谱“ 的点并不会收到大的关注，这在直觉上不是很合适，因而常使用其他的代理损失函数进行优化。

0-1损失公式：
![img](https://img2018.cnblogs.com/blog/981211/201810/981211-20181022182728777-1949041372.png)

其中yf(x) > 0 ，则样本分类正确， yf(x) < 0 则分类错误，而相应的分类决策边界即为 f(x) = 0 。



## 2）平均绝对误差损失 

## Mean Absolute Error Loss

### 基本形式与原理

也称为 L1 Loss

![[公式]](https://www.zhihu.com/equation?tex=+J_%7BMAE%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Cleft+%7C+y_i+-+%5Chat%7By_i%7D+%5Cright+%7C+%5C%5C)

同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差 ![[公式]](https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert) 的增加，MAE 损失呈线性增长

![img](https://pic3.zhimg.com/80/v2-fd248542b6b5aa9fadcab44340045dee_hd.jpg)

3）均方差 [Mean Squared Error (MSE)](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Mean_squared_error) 损失是机器学习、深度学习回归任务中最常用的一种损失函数，也称为 L2 Loss。其基本形式如下

![[公式]](https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C)

从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值 ![[公式]](https://www.zhihu.com/equation?tex=y%3D0) ，不同的预测值 ![[公式]](https://www.zhihu.com/equation?tex=%5B-1.5%2C+1.5%5D) 的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差 ![[公式]](https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert) 的增加，均方差损失呈二次方地增加。

![img](https://pic1.zhimg.com/80/v2-f13a4355c21d16cad8b3f30e8a24b5cc_hd.jpg)











### 4）log对数损失函数

对数损失, 即对数似然损失(Log-likelihood Loss), 也称逻辑斯谛回归损失(Logistic Loss)或交叉熵损失(cross-entropy Loss), 是在概率估计上定义的.它常用于逻辑回归和神经网络,以及一些期望极大算法的变体. 可用于评估分类器的概率输出.

对数损失的公式为：

![img](https://img2018.cnblogs.com/blog/981211/201810/981211-20181022121857619-1433190203.png)

其中, Y 为输出变量, X为输入变量, L 为损失函数. N为输入样本量, M为类别数, yij 是表示类别 j 是否是输入实例 xi 的真实类别. pij 为模型或分类器预测输入实例 xi 属于类别 j 的概率。

如果目标是进行二分类，则损失函数可以简化为：

![img](https://img2018.cnblogs.com/blog/981211/201810/981211-20181022122334762-693433742.png)



### 5）指数损失函数

指数损失是在原有的损失函数上套一层指数，在adaboost上使用的就是指数损失，在加性模型中指数损失的主要吸引点在于计算上的方便。

指数损失公式：
![img](https://img2018.cnblogs.com/blog/981211/201810/981211-20181022174604258-1922940550.png)

其中n为样本数量，yi是样本的真实值，f(xi)是第i次迭代模型的权重。









![[公式]](https://www.zhihu.com/equation?tex=J%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+f%28y_i%2C%5Chat%7By_i%7D%29)









## 6）合页损失 Hinge Loss

合页损失 [Hinge Loss](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Hinge_loss) 是另外一种二分类损失函数，适用于 maximum-margin 的分类，支持向量机 Support Vector Machine (SVM) 模型的损失函数本质上就是 Hinge Loss + L2 正则化。合页损失的公式如下

![[公式]](https://www.zhihu.com/equation?tex=J_%7Bhinge%7D%3D%5Csum_%7Bi%3D1%7D%5EN%5Coperatorname%7Bmax%7D%5Cleft%280%2C+1-%5Cmathbb%7Bsgn%7D%28y_i%29%5Chat%7By_i%7D%5Cright%29++%5C%5C)

下图是 ![[公式]](https://www.zhihu.com/equation?tex=y) 为正类， 即 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathbb%7Bsgn%7D%28y%29+%3D+1) 时，不同输出的合页损失示意图

![img](https://pic4.zhimg.com/80/v2-678fe676ad9dfd82d943eea56da26ecf_hd.jpg)

可以看到当 ![[公式]](https://www.zhihu.com/equation?tex=y) 为正类时，模型输出负值会有较大的惩罚，当模型输出为正值且在 ![[公式]](https://www.zhihu.com/equation?tex=%280%2C+1%29) 区间时还会有一个较小的惩罚。即合页损失不仅惩罚预测错的，并且对于预测对了但是置信度不高的也会给一个惩罚，只有置信度高的才会有零损失。使用合页损失直觉上理解是要**找到一个决策边界，使得所有数据点被这个边界正确地、高置信地被分类**。





优化算法：

常用的优化算法包括：梯度下降法（Gradient Descent），共轭梯度法（Conjugate Gradient），Momentum算法及其变体，牛顿法和拟牛顿法（包括L-BFGS），AdaGrad，Adadelta，RMSprop，Adam及其变体，Nadam。

梯度下降法（Gradient Descent）
  通过每次在当前梯度方向（最陡峭的方向）向前“迈”一步，来逐渐逼近函数的最小值。
  在第nn次迭代中，参数θn=θn−1+Δθθn=θn−1+Δθ
  我们将损失函数在θn−1θn−1处进行一阶泰勒展开：
L(θn)=L(θn−1+Δθ)≈L(θn−1)+L′(θn−1)Δθ
L(θn)=L(θn−1+Δθ)≈L(θn−1)+L′(θn−1)Δθ

  为了使L(θn)<L(θn−1)L(θn)<L(θn−1)，可取Δθ=−αL′(θn−1)Δθ=−αL′(θn−1)，即得到梯度下降的迭代公式:
θn:=θn−1−αL′(θn−1)

  梯度下降法根据每次求解损失函数LL带入的样本数，可以分为：全量梯度下降（计算所有样本的损失），批量梯度下降（每次计算一个batch样本的损失）和随机梯度下降（每次随机选取一个样本计算损失）。

2）随即梯度下降



SGD的优缺点
优点：操作简单，计算量小，在损失函数是凸函数的情况下能够保证收敛到一个较好的全局最优解。
缺点：

αα是个定值（在最原始的版本），它的选取直接决定了解的好坏，过小会导致收敛太慢，过大会导致震荡而无法收敛到最优解。

对于非凸问题，只能收敛到局部最优，并且没有任何摆脱局部最优的能力（一旦梯度为0就不会再有任何变化）。
PS：对于非凸的优化问题，我们可以将其转化为对偶问题，对偶函数一定是凹函数，但是这样求出来的解并不等价于原函数的解，只是原函数的一个确下界
Momentum
  SGD中，每次的步长一致，并且方向都是当前梯度的方向，这会收敛的不稳定性：无论在什么位置，总是以相同的“步子”向前迈。
  

3）批梯度下降





4）

Momentum的思想就是模拟物体运动的惯性：当我们跑步时转弯，我们最终的前进方向是由我们之前的方向和转弯的方向共同决定的。Momentum在每次更新时，保留一部分上次的更新方向：
Δθn=ρΔθn−1+gn−1
Δθn=ρΔθn−1+gn−1
θn:=θn−1−αΔθn
θn:=θn−1−αΔθn

  这里ρρ值决定了保留多少上次更新方向的信息，值为0~1，初始时可以取0.5，随着迭代逐渐增大；αα为学习率，同SGD。
优点：一定程度上缓解了SGD收敛不稳定的问题，并且有一定的摆脱局部最优的能力（当前梯度为0时，仍可能按照上次迭代的方向冲出局部最优点），直观上理解，它可以让每次迭代的“掉头方向不是那个大“。左图为SGD，右图为Momentum。

缺点：这里又多了另外一个超参数ρρ需要我们设置，它的选取同样会影响到结果。

Nesterov Momentum
  Nesterov Momentum又叫做Nesterov Accelerated Gradient（NAG），是基于Momentum的加速算法。
  通过上述，我们知道，在每次更新的时候，都在ρΔθn−1+L′(θn)ρΔθn−1+L′(θn)走αα这么远，那么我们为什么不直接走到这个位置，然后从这个位置的梯度再走一次呢？为此，引出NAG的迭代公式：
Δθn=ρΔθn−1+g(θn−1−αΔθn−1)
Δθn=ρΔθn−1+g(θn−1−αΔθn−1)
θn:=θn−1−αΔθn
θn:=θn−1−αΔθn

  我们可以这样理解，每次走之前，我们先用一个棍子往前探一探，这根棍子探到的位置就是L(θn−1−αΔθn−1)L(θn−1−αΔθn−1)，然后我们求解此处的梯度：如果梯度大，我们迈一大步，反之，迈一小步。如果我们将上式改写一下：
Δθn=ρΔθn−1+gn−1+ρ(gn−1−gn−2))
Δθn=ρΔθn−1+gn−1+ρ(gn−1−gn−2))
θn:=θn−1−αΔθn
θn:=θn−1−αΔθn

  如果这次的梯度比上次大，那么我们有理由认为梯度还会继续变大！于是，当前就迈一大步，因为使用了二阶导数的信息（二阶导数>0即一阶导单调递增，也即g′n−1>g′n−2gn−1′>gn−2′，因此可以加快收敛。

图片来自Hinton在Coursera上DL课程的slides

  蓝色的线代表原始的Momentum更新方向，在NAG中，我们先求解得到了这个方向，也即棕色的线，然后求解此处的梯度（红色的线），从而得到最终的前进方向。

共轭梯度法（Conjugate Gradient）
  同样的，CG也在选取前进方向上，对SGD做了改动。它对性能有很大的提升，但是不适用高维数据，求解共轭的计算量过大。网上有很多讲CG的，但是个人感觉都是从某一篇文献里面摘出来的几个图，这里推荐一个专门讲解CG的painless conjugate gradient，讲的很细致。

  不同于上述算法对前进方向进行选择和调整，后面这些算法主要研究沿着梯度方向走多远的问题，也即如何选择合适的学习率αα。

5）自适应性梯度法 Adagrad
  adaptive gradient。它通过记录每次迭代过程中的前进方向和距离，从而使得针对不同问题，有一套自适应调整学习率的方法：
Δθn=1∑n−1i=1gi+ϵ‾‾‾‾‾‾‾‾‾‾‾√gn−1
Δθn=1∑i=1n−1gi+ϵgn−1
θn:=θn−1−αΔθn
θn:=θn−1−αΔθn

  可以看到，随着迭代的增加，我们的学习率是在逐渐变小的，这在“直观上”是正确的：当我们越接近最优解时，函数的“坡度”会越平缓，我们也必须走的更慢来保证不会穿过最优解。这个变小的幅度只跟当前问题的函数梯度有关，ϵϵ是为了防止0除，一般取1e-7。
优点：解决了SGD中学习率不能自适应调整的问题
缺点：

学习率单调递减，在迭代后期可能导致学习率变得特别小而导致收敛及其缓慢。
同样的，我们还需要手动设置初始αα



牛顿法
  牛顿法不仅使用了一阶导信息，同时还利用了二阶导来更新参数，其形式化的公式如下：
θn:=θn−1−αL′n−1L″n−1
θn:=θn−1−αLn−1′Ln−1″

  回顾之前的θn=θn−1+Δθθn=θn−1+Δθ，我们将损失函数在θn−1θn−1处进行二阶泰勒展开：
L(θn)=L(θn−1+Δθ)≈L(θn−1)+L′(θn−1)Δθ+L″(θn−1)Δθ22
L(θn)=L(θn−1+Δθ)≈L(θn−1)+L′(θn−1)Δθ+L″(θn−1)Δθ22

  要使L(θn)<L(θn−1)L(θn)<L(θn−1)，我们需要极小化L′(θn−1)Δθ+L″(θn−1)Δθ22L′(θn−1)Δθ+L″(θn−1)Δθ22，对其求导，令导数为零，可以得到：
Δθ=−L′n−1L″n−1
Δθ=−Ln−1′Ln−1″

  也即牛顿法的迭代公式，拓展到高维数据，二阶导变为Hession矩阵，上式变为：
Δθ=−H−1L′n−1
Δθ=−H−1Ln−1′
  直观上，我们可以这样理解：我们要求一个函数的极值，假设只有一个全局最优值，我们需要求得其导数为0的地方，我们把下图想成是损失函数的导数的图像f(x)f(x)，那么：
k=tanθ=f′(x0)=f(x0)x0−x1→x1=x0−f(x0)f′(x0)
k=tan⁡θ=f′(x0)=f(x0)x0−x1→x1=x0−f(x0)f′(x0)

  我们一直这样做切线，最终xnxn将逼近与f′(x)f′(x)的0点，对于原函数而言，即Δθ=−L′n−1L″n−1Δθ=−Ln−1′Ln−1″。


